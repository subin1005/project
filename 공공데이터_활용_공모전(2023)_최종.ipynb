{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subin1005/project/blob/main/%EA%B3%B5%EA%B3%B5%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%99%9C%EC%9A%A9_%EA%B3%B5%EB%AA%A8%EC%A0%84(2023)_%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxsc44MujND3"
      },
      "source": [
        "# 공공데이터 활용 공모전 (분석과제 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqHQW9LAjRTY"
      },
      "source": [
        "### 1. 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L2Feq-zjTSs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import torch, random, os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시드 고정"
      ],
      "metadata": {
        "id": "0bcDNgTCOuri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "BgookkXI6Y9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBfiXtMxjT8X"
      },
      "source": [
        "### 2. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ncua5rSjVDz",
        "outputId": "8893110f-ae78-499c-c0f8-85020cffb88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNzt6LCMl0Qp"
      },
      "outputs": [],
      "source": [
        "# 전력데이터\n",
        "# power_1 : 2012년 6월 1일 - 2022년 4월 7일\n",
        "# power_2 : 2022년 4월 1일 - 2023년 4월 30일\n",
        "power_1 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/전력데이터/[2012-2022] 한국전력거래소_5분단위 전력수급현황_20220407.csv', encoding = 'cp949')\n",
        "power_2 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/전력데이터/[2022-2023]한국전력거래소_5분단위 전력수급현황_20230430.csv', encoding = 'cp949') # 2022 4월 ~ 2023 4월"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 태양광, 풍력 발전량 데이터\n",
        "# energy1 : 2017년 1월 1일 - 2023년 2월 28일\n",
        "# enregy2 : 2023년 3월 1일 - 2023년 5월 31일\n",
        "energy1 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/에너지/한국전력거래소_지역별 시간별 태양광 발전량_20230228.csv', encoding = 'cp949')\n",
        "energy2 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/에너지/한국전력거래소_지역별 시간별 태양광 발전량_20230531.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "SObR89fR76eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2020 날씨데이터\n",
        "Gangwon_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/강원도_2020.csv', encoding = 'cp949')\n",
        "Gyeonggi_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경기도_2020.csv', encoding = 'cp949')\n",
        "Gyeongsangnam_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상남도_2020.csv', encoding = 'cp949')\n",
        "Gyeongsangbuk_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상북도_2020.csv', encoding = 'cp949')\n",
        "Gwangju_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/광주_2020.csv', encoding = 'cp949')\n",
        "Daegu_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대구_2020.csv', encoding = 'cp949')\n",
        "Daejeon_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대전_2020.csv', encoding = 'cp949')\n",
        "Busan_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/부산_2020.csv', encoding = 'cp949')\n",
        "Seoul_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/서울_2020.csv', encoding = 'cp949')\n",
        "Sejong_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/세종_2020.csv', encoding = 'cp949')\n",
        "Ulsan_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/울산_2020.csv', encoding = 'cp949')\n",
        "Incheon_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/인천_2020.csv', encoding = 'cp949')\n",
        "Jeollanam_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라남도_2020.csv', encoding = 'cp949')\n",
        "Jeollabuk_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라북도_2020.csv', encoding = 'cp949')\n",
        "Jeju_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/제주도_2020.csv', encoding = 'cp949')\n",
        "Chungcheongnam_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청남도_2020.csv', encoding = 'cp949')\n",
        "Chungcheongbuk_2020 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청북도_2020.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "97dJ9QSDao94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021 날씨데이터\n",
        "Gangwon_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/강원도_2021.csv', encoding = 'cp949')\n",
        "Gyeonggi_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경기도_2021.csv', encoding = 'cp949')\n",
        "Gyeongsangnam_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상남도_2021.csv', encoding = 'cp949')\n",
        "Gyeongsangbuk_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상북도_2021.csv', encoding = 'cp949')\n",
        "Gwangju_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/광주_2021.csv', encoding = 'cp949')\n",
        "Daegu_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대구_2021.csv', encoding = 'cp949')\n",
        "Daejeon_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대전_2021.csv', encoding = 'cp949')\n",
        "Busan_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/부산_2021.csv', encoding = 'cp949')\n",
        "Seoul_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/서울_2021.csv', encoding = 'cp949')\n",
        "Sejong_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/세종_2021.csv', encoding = 'cp949')\n",
        "Ulsan_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/울산_2021.csv', encoding = 'cp949')\n",
        "Incheon_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/인천_2021.csv', encoding = 'cp949')\n",
        "Jeollanam_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라남도_2021.csv', encoding = 'cp949')\n",
        "Jeollabuk_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라북도_2021.csv', encoding = 'cp949')\n",
        "Jeju_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/제주도_2021.csv', encoding = 'cp949')\n",
        "Chungcheongnam_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청남도_2021.csv', encoding = 'cp949')\n",
        "Chungcheongbuk_2021 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청북도_2021.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "pvu6kxPLYyRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2022 날씨데이터\n",
        "Gangwon_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/강원도_2022.csv', encoding = 'cp949')\n",
        "Gyeonggi_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경기도_2022.csv', encoding = 'cp949')\n",
        "Gyeongsangnam_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상남도_2022.csv', encoding = 'cp949')\n",
        "Gyeongsangbuk_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상북도_2022.csv', encoding = 'cp949')\n",
        "Gwangju_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/광주_2022.csv', encoding = 'cp949')\n",
        "Daegu_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대구_2022.csv', encoding = 'cp949')\n",
        "Daejeon_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대전_2022.csv', encoding = 'cp949')\n",
        "Busan_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/부산_2022.csv', encoding = 'cp949')\n",
        "Seoul_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/서울_2022.csv', encoding = 'cp949')\n",
        "Sejong_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/세종_2022.csv', encoding = 'cp949')\n",
        "Ulsan_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/울산_2022.csv', encoding = 'cp949')\n",
        "Incheon_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/인천_2022.csv', encoding = 'cp949')\n",
        "Jeollanam_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라남도_2022.csv', encoding = 'cp949')\n",
        "Jeollabuk_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라북도_2022.csv', encoding = 'cp949')\n",
        "Jeju_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/제주도_2022.csv', encoding = 'cp949')\n",
        "Chungcheongnam_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청남도_2022.csv', encoding = 'cp949')\n",
        "Chungcheongbuk_2022 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청북도_2022.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "rkpn0m2-Yy4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 2023 날씨데이터\n",
        "Gangwon_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/강원도_2023.csv', encoding = 'cp949')\n",
        "Gyeonggi_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경기도_2023.csv', encoding = 'cp949')\n",
        "Gyeongsangnam_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상남도_2023.csv', encoding = 'cp949')\n",
        "Gyeongsangbuk_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상북도_2023.csv', encoding = 'cp949')\n",
        "Gwangju_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/광주_2023.csv', encoding = 'cp949')\n",
        "Daegu_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대구_2023.csv', encoding = 'cp949')\n",
        "Daejeon_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대전_2023.csv', encoding = 'cp949')\n",
        "Busan_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/부산_2023.csv', encoding = 'cp949')\n",
        "Seoul_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/서울_2023.csv', encoding = 'cp949')\n",
        "Sejong_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/세종_2023.csv', encoding = 'cp949')\n",
        "Ulsan_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/울산_2023.csv', encoding = 'cp949')\n",
        "Incheon_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/인천_2023.csv', encoding = 'cp949')\n",
        "Jeollanam_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라남도_2023.csv', encoding = 'cp949')\n",
        "Jeollabuk_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라북도_2023.csv', encoding = 'cp949')\n",
        "Jeju_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/제주도_2023.csv', encoding = 'cp949')\n",
        "Chungcheongnam_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청남도_2023.csv', encoding = 'cp949')\n",
        "Chungcheongbuk_2023 = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청북도_2023.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "QW8_dnag9KUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 날씨데이터\n",
        "Gangwon_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/강원도_test1.csv', encoding = 'cp949')\n",
        "Gyeonggi_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경기도_test1.csv', encoding = 'cp949')\n",
        "Gyeongsangnam_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상남도_test1.csv', encoding = 'cp949')\n",
        "Gyeongsangbuk_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/경상북도_test1.csv', encoding = 'cp949')\n",
        "Gwangju_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/광주_test1.csv', encoding = 'cp949')\n",
        "Daegu_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대구_test1.csv', encoding = 'cp949')\n",
        "Daejeon_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/대전_test1.csv', encoding = 'cp949')\n",
        "Busan_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/부산_test1.csv', encoding = 'cp949')\n",
        "Seoul_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/서울_test1.csv', encoding = 'cp949')\n",
        "Sejong_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/세종_test1.csv', encoding = 'cp949')\n",
        "Ulsan_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/울산_test1.csv', encoding = 'cp949')\n",
        "Incheon_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/인천_test1.csv', encoding = 'cp949')\n",
        "Jeollanam_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라남도_test1.csv', encoding = 'cp949')\n",
        "Jeollabuk_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/전라북도_test1.csv', encoding = 'cp949')\n",
        "Jeju_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/제주도_test1.csv', encoding = 'cp949')\n",
        "Chungcheongnam_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청남도_test1.csv', encoding = 'cp949')\n",
        "Chungcheongbuk_test = pd.read_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/날씨데이터/충청북도_test1.csv', encoding = 'cp949')"
      ],
      "metadata": {
        "id": "cWxbgtqH9Xyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6cJxB-tm1-j"
      },
      "source": [
        "### 3. 데이터 탐색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g3XbK3AnMAQ",
        "outputId": "5b055fa2-137a-4da5-8a36-760454fa950e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "기준일시          0\n",
              "공급능력(MW)      0\n",
              "현재수요(MW)      0\n",
              "최대예측수요(MW)    0\n",
              "공급예비력(MW)     0\n",
              "공급예비율(퍼센트)    0\n",
              "운영예비력(MW)     0\n",
              "운영예비율(퍼센트)    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 전력 데이터 결측치 없음\n",
        "power_1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_2.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3tJWE7vQDgp",
        "outputId": "33e9f5c9-0df5-4386-eafe-477a9d6e1c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "기준일시          0\n",
              "공급능력(MW)      0\n",
              "현재수요(MW)      0\n",
              "최대예측수요(MW)    0\n",
              "공급예비력(MW)     0\n",
              "공급예비율(퍼센트)    0\n",
              "운영예비력(MW)     0\n",
              "운영예비율(퍼센트)    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "energy1.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd4E-X1wAcX1",
        "outputId": "3144e0d1-7c93-4d34-da1f-cc3c1c464c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "거래일자                   0\n",
              "거래시간                   0\n",
              "지역                     0\n",
              " 태양광 발전량(MWh)          0\n",
              " 풍력 발전량(MWh)      324000\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "energy2.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNrpG0vtAeY4",
        "outputId": "92aabf74-7c9f-4656-e271-cad9eb1356b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "거래일자                0\n",
              "거래시간                0\n",
              "지역                  0\n",
              "  태양광 발전량(MWh)      0\n",
              "  풍력 발전량(MWh)       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "energy1의 풍력 발전량에 324,000개의 결측치 존재"
      ],
      "metadata": {
        "id": "OpzuLt-XTjQB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLX0wEtUUtT"
      },
      "source": [
        "### 4. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0BsArXOVGwO"
      },
      "source": [
        "#### (1) 지역별 날씨데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시도의 일시로 그룹화"
      ],
      "metadata": {
        "id": "w2288qMSpbVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oFiPjAF9-88"
      },
      "outputs": [],
      "source": [
        "Gangwondo_2020 = Gangwon_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeonggido_2020 = Gyeonggi_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangnamdo_2020 = Gyeongsangnam_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangbukdo_2020 = Gyeongsangbuk_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gwangjusi_2020 = Gwangju_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daegusi_2020 = Daegu_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daejeonsi_2020 = Daejeon_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Busansi_2020 = Busan_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Seoulsi_2020 = Seoul_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Sejongsi_2020 = Sejong_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Ulsansi_2020 = Ulsan_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Incheonsi_2020 = Incheon_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollanamdo_2020 = Jeollanam_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollabukdo_2020 = Jeollabuk_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jejudo_2020 = Jeju_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongnamdo_2020 = Chungcheongnam_2020.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongbukdo_2020 = Chungcheongbuk_2020.drop('지점명', axis = 1).groupby('일시').mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2021 = Gangwon_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeonggido_2021 = Gyeonggi_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangnamdo_2021 = Gyeongsangnam_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangbukdo_2021 = Gyeongsangbuk_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gwangjusi_2021 = Gwangju_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daegusi_2021 = Daegu_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daejeonsi_2021 = Daejeon_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Busansi_2021 = Busan_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Seoulsi_2021 = Seoul_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Sejongsi_2021 = Sejong_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Ulsansi_2021 = Ulsan_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Incheonsi_2021 = Incheon_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollanamdo_2021 = Jeollanam_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollabukdo_2021 = Jeollabuk_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jejudo_2021 = Jeju_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongnamdo_2021 = Chungcheongnam_2021.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongbukdo_2021 = Chungcheongbuk_2021.drop('지점명', axis = 1).groupby('일시').mean()"
      ],
      "metadata": {
        "id": "qSOVyH_4exLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2022 = Gangwon_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeonggido_2022 = Gyeonggi_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangnamdo_2022 = Gyeongsangnam_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangbukdo_2022 = Gyeongsangbuk_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gwangjusi_2022 = Gwangju_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daegusi_2022 = Daegu_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daejeonsi_2022 = Daejeon_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Busansi_2022 = Busan_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Seoulsi_2022 = Seoul_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Sejongsi_2022 = Sejong_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Ulsansi_2022 = Ulsan_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Incheonsi_2022 = Incheon_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollanamdo_2022 = Jeollanam_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollabukdo_2022 = Jeollabuk_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jejudo_2022 = Jeju_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongnamdo_2022 = Chungcheongnam_2022.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongbukdo_2022 = Chungcheongbuk_2022.drop('지점명', axis = 1).groupby('일시').mean()"
      ],
      "metadata": {
        "id": "TqQ5CBSTcLLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2023 = Gangwon_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeonggido_2023 = Gyeonggi_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangnamdo_2023 = Gyeongsangnam_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangbukdo_2023 = Gyeongsangbuk_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gwangjusi_2023 = Gwangju_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daegusi_2023 = Daegu_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daejeonsi_2023 = Daejeon_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Busansi_2023 = Busan_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Seoulsi_2023 = Seoul_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Sejongsi_2023 = Sejong_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Ulsansi_2023 = Ulsan_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Incheonsi_2023 = Incheon_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollanamdo_2023 = Jeollanam_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollabukdo_2023 = Jeollabuk_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jejudo_2023 = Jeju_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongnamdo_2023 = Chungcheongnam_2023.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongbukdo_2023 = Chungcheongbuk_2023.drop('지점명', axis = 1).groupby('일시').mean()"
      ],
      "metadata": {
        "id": "OlJ5VSXLfS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_test = Gangwon_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeonggido_test = Gyeonggi_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangnamdo_test = Gyeongsangnam_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gyeongsangbukdo_test = Gyeongsangbuk_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Gwangjusi_test = Gwangju_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daegusi_test = Daegu_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Daejeonsi_test = Daejeon_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Busansi_test = Busan_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Seoulsi_test = Seoul_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Sejongsi_test = Sejong_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Ulsansi_test = Ulsan_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Incheonsi_test = Incheon_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollanamdo_test = Jeollanam_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jeollabukdo_test = Jeollabuk_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Jejudo_test = Jeju_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongnamdo_test = Chungcheongnam_test.drop('지점명', axis = 1).groupby('일시').mean()\n",
        "Chungcheongbukdo_test = Chungcheongbuk_test.drop('지점명', axis = 1).groupby('일시').mean()"
      ],
      "metadata": {
        "id": "73zpzLwF-Vzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 강수량의 결측을 0으로 대치"
      ],
      "metadata": {
        "id": "hJ6QlXZnlUHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEFkVErlJ9Jt"
      },
      "outputs": [],
      "source": [
        "# 모든 강수량 결측치 0으로 대치 (강수량 결측을 0으로 추정)\n",
        "Gangwondo_2020['강수량(mm)'] = Gangwondo_2020['강수량(mm)'].fillna(0)\n",
        "Gyeonggido_2020['강수량(mm)'] = Gyeonggido_2020['강수량(mm)'].fillna(0)\n",
        "Gyeongsangnamdo_2020['강수량(mm)'] = Gyeongsangnamdo_2020['강수량(mm)'].fillna(0)\n",
        "Gyeongsangbukdo_2020['강수량(mm)'] = Gyeongsangbukdo_2020['강수량(mm)'].fillna(0)\n",
        "Gwangjusi_2020['강수량(mm)'] = Gwangjusi_2020['강수량(mm)'].fillna(0)\n",
        "Daegusi_2020['강수량(mm)'] = Daegusi_2020['강수량(mm)'].fillna(0)\n",
        "Daejeonsi_2020['강수량(mm)'] = Daejeonsi_2020['강수량(mm)'].fillna(0)\n",
        "Busansi_2020['강수량(mm)'] = Busansi_2020['강수량(mm)'].fillna(0)\n",
        "Seoulsi_2020['강수량(mm)'] = Seoulsi_2020['강수량(mm)'].fillna(0)\n",
        "Sejongsi_2020['강수량(mm)'] = Sejongsi_2020['강수량(mm)'].fillna(0)\n",
        "Ulsansi_2020['강수량(mm)'] = Ulsansi_2020['강수량(mm)'].fillna(0)\n",
        "Incheonsi_2020['강수량(mm)'] = Incheonsi_2020['강수량(mm)'].fillna(0)\n",
        "Jeollanamdo_2020['강수량(mm)'] = Jeollanamdo_2020['강수량(mm)'].fillna(0)\n",
        "Jeollabukdo_2020['강수량(mm)'] = Jeollabukdo_2020['강수량(mm)'].fillna(0)\n",
        "Jejudo_2020['강수량(mm)'] = Jejudo_2020['강수량(mm)'].fillna(0)\n",
        "Chungcheongnamdo_2020['강수량(mm)'] = Chungcheongnamdo_2020['강수량(mm)'].fillna(0)\n",
        "Chungcheongbukdo_2020['강수량(mm)'] = Chungcheongbukdo_2020['강수량(mm)'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 강수량 결측치 0으로 대치 (강수량 결측을 0으로 추정)\n",
        "Gangwondo_2021['강수량(mm)'] = Gangwondo_2021['강수량(mm)'].fillna(0)\n",
        "Gyeonggido_2021['강수량(mm)'] = Gyeonggido_2021['강수량(mm)'].fillna(0)\n",
        "Gyeongsangnamdo_2021['강수량(mm)'] = Gyeongsangnamdo_2021['강수량(mm)'].fillna(0)\n",
        "Gyeongsangbukdo_2021['강수량(mm)'] = Gyeongsangbukdo_2021['강수량(mm)'].fillna(0)\n",
        "Gwangjusi_2021['강수량(mm)'] = Gwangjusi_2021['강수량(mm)'].fillna(0)\n",
        "Daegusi_2021['강수량(mm)'] = Daegusi_2021['강수량(mm)'].fillna(0)\n",
        "Daejeonsi_2021['강수량(mm)'] = Daejeonsi_2021['강수량(mm)'].fillna(0)\n",
        "Busansi_2021['강수량(mm)'] = Busansi_2021['강수량(mm)'].fillna(0)\n",
        "Seoulsi_2021['강수량(mm)'] = Seoulsi_2021['강수량(mm)'].fillna(0)\n",
        "Sejongsi_2021['강수량(mm)'] = Sejongsi_2021['강수량(mm)'].fillna(0)\n",
        "Ulsansi_2021['강수량(mm)'] = Ulsansi_2021['강수량(mm)'].fillna(0)\n",
        "Incheonsi_2021['강수량(mm)'] = Incheonsi_2021['강수량(mm)'].fillna(0)\n",
        "Jeollanamdo_2021['강수량(mm)'] = Jeollanamdo_2021['강수량(mm)'].fillna(0)\n",
        "Jeollabukdo_2021['강수량(mm)'] = Jeollabukdo_2021['강수량(mm)'].fillna(0)\n",
        "Jejudo_2021['강수량(mm)'] = Jejudo_2021['강수량(mm)'].fillna(0)\n",
        "Chungcheongnamdo_2021['강수량(mm)'] = Chungcheongnamdo_2021['강수량(mm)'].fillna(0)\n",
        "Chungcheongbukdo_2021['강수량(mm)'] = Chungcheongbukdo_2021['강수량(mm)'].fillna(0)"
      ],
      "metadata": {
        "id": "6VMzxzjakjCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 강수량 결측치 0으로 대치 (강수량 결측을 0으로 추정)\n",
        "Gangwondo_2022['강수량(mm)'] = Gangwondo_2022['강수량(mm)'].fillna(0)\n",
        "Gyeonggido_2022['강수량(mm)'] = Gyeonggido_2022['강수량(mm)'].fillna(0)\n",
        "Gyeongsangnamdo_2022['강수량(mm)'] = Gyeongsangnamdo_2022['강수량(mm)'].fillna(0)\n",
        "Gyeongsangbukdo_2022['강수량(mm)'] = Gyeongsangbukdo_2022['강수량(mm)'].fillna(0)\n",
        "Gwangjusi_2022['강수량(mm)'] = Gwangjusi_2022['강수량(mm)'].fillna(0)\n",
        "Daegusi_2022['강수량(mm)'] = Daegusi_2022['강수량(mm)'].fillna(0)\n",
        "Daejeonsi_2022['강수량(mm)'] = Daejeonsi_2022['강수량(mm)'].fillna(0)\n",
        "Busansi_2022['강수량(mm)'] = Busansi_2022['강수량(mm)'].fillna(0)\n",
        "Seoulsi_2022['강수량(mm)'] = Seoulsi_2022['강수량(mm)'].fillna(0)\n",
        "Sejongsi_2022['강수량(mm)'] = Sejongsi_2022['강수량(mm)'].fillna(0)\n",
        "Ulsansi_2022['강수량(mm)'] = Ulsansi_2022['강수량(mm)'].fillna(0)\n",
        "Incheonsi_2022['강수량(mm)'] = Incheonsi_2022['강수량(mm)'].fillna(0)\n",
        "Jeollanamdo_2022['강수량(mm)'] = Jeollanamdo_2022['강수량(mm)'].fillna(0)\n",
        "Jeollabukdo_2022['강수량(mm)'] = Jeollabukdo_2022['강수량(mm)'].fillna(0)\n",
        "Jejudo_2022['강수량(mm)'] = Jejudo_2022['강수량(mm)'].fillna(0)\n",
        "Chungcheongnamdo_2022['강수량(mm)'] = Chungcheongnamdo_2022['강수량(mm)'].fillna(0)\n",
        "Chungcheongbukdo_2022['강수량(mm)'] = Chungcheongbukdo_2022['강수량(mm)'].fillna(0)"
      ],
      "metadata": {
        "id": "-Vk7aOApk0D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 강수량 결측치 0으로 대치 (강수량 결측을 0으로 추정)\n",
        "Gangwondo_2023['강수량(mm)'] = Gangwondo_2023['강수량(mm)'].fillna(0)\n",
        "Gyeonggido_2023['강수량(mm)'] = Gyeonggido_2023['강수량(mm)'].fillna(0)\n",
        "Gyeongsangnamdo_2023['강수량(mm)'] = Gyeongsangnamdo_2023['강수량(mm)'].fillna(0)\n",
        "Gyeongsangbukdo_2023['강수량(mm)'] = Gyeongsangbukdo_2023['강수량(mm)'].fillna(0)\n",
        "Gwangjusi_2023['강수량(mm)'] = Gwangjusi_2023['강수량(mm)'].fillna(0)\n",
        "Daegusi_2023['강수량(mm)'] = Daegusi_2023['강수량(mm)'].fillna(0)\n",
        "Daejeonsi_2023['강수량(mm)'] = Daejeonsi_2023['강수량(mm)'].fillna(0)\n",
        "Busansi_2023['강수량(mm)'] = Busansi_2023['강수량(mm)'].fillna(0)\n",
        "Seoulsi_2023['강수량(mm)'] = Seoulsi_2023['강수량(mm)'].fillna(0)\n",
        "Sejongsi_2023['강수량(mm)'] = Sejongsi_2023['강수량(mm)'].fillna(0)\n",
        "Ulsansi_2023['강수량(mm)'] = Ulsansi_2023['강수량(mm)'].fillna(0)\n",
        "Incheonsi_2023['강수량(mm)'] = Incheonsi_2023['강수량(mm)'].fillna(0)\n",
        "Jeollanamdo_2023['강수량(mm)'] = Jeollanamdo_2023['강수량(mm)'].fillna(0)\n",
        "Jeollabukdo_2023['강수량(mm)'] = Jeollabukdo_2023['강수량(mm)'].fillna(0)\n",
        "Jejudo_2023['강수량(mm)'] = Jejudo_2023['강수량(mm)'].fillna(0)\n",
        "Chungcheongnamdo_2023['강수량(mm)'] = Chungcheongnamdo_2023['강수량(mm)'].fillna(0)\n",
        "Chungcheongbukdo_2023['강수량(mm)'] = Chungcheongbukdo_2023['강수량(mm)'].fillna(0)"
      ],
      "metadata": {
        "id": "43ps8ARMlCfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 강수량 결측치 0으로 대치 (강수량 결측을 0으로 추정)\n",
        "Gangwondo_test['강수량(mm)'] = Gangwondo_test['강수량(mm)'].fillna(0)\n",
        "Gyeonggido_test['강수량(mm)'] = Gyeonggido_test['강수량(mm)'].fillna(0)\n",
        "Gyeongsangnamdo_test['강수량(mm)'] = Gyeongsangnamdo_test['강수량(mm)'].fillna(0)\n",
        "Gyeongsangbukdo_test['강수량(mm)'] = Gyeongsangbukdo_test['강수량(mm)'].fillna(0)\n",
        "Gwangjusi_test['강수량(mm)'] = Gwangjusi_test['강수량(mm)'].fillna(0)\n",
        "Daegusi_test['강수량(mm)'] = Daegusi_test['강수량(mm)'].fillna(0)\n",
        "Daejeonsi_test['강수량(mm)'] = Daejeonsi_test['강수량(mm)'].fillna(0)\n",
        "Busansi_test['강수량(mm)'] = Busansi_test['강수량(mm)'].fillna(0)\n",
        "Seoulsi_test['강수량(mm)'] = Seoulsi_test['강수량(mm)'].fillna(0)\n",
        "Sejongsi_test['강수량(mm)'] = Sejongsi_test['강수량(mm)'].fillna(0)\n",
        "Ulsansi_test['강수량(mm)'] = Ulsansi_test['강수량(mm)'].fillna(0)\n",
        "Incheonsi_test['강수량(mm)'] = Incheonsi_test['강수량(mm)'].fillna(0)\n",
        "Jeollanamdo_test['강수량(mm)'] = Jeollanamdo_test['강수량(mm)'].fillna(0)\n",
        "Jeollabukdo_test['강수량(mm)'] = Jeollabukdo_test['강수량(mm)'].fillna(0)\n",
        "Jejudo_test['강수량(mm)'] = Jejudo_test['강수량(mm)'].fillna(0)\n",
        "Chungcheongnamdo_test['강수량(mm)'] = Chungcheongnamdo_test['강수량(mm)'].fillna(0)\n",
        "Chungcheongbukdo_test['강수량(mm)'] = Chungcheongbukdo_test['강수량(mm)'].fillna(0)"
      ],
      "metadata": {
        "id": "d9P1hmWA-51W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 그 외 결측을 평균값으로 대치 (강수량을 제외한 모든 변수는 결측량이 적기 때문)"
      ],
      "metadata": {
        "id": "14btaGSDlaEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2020 = Gangwondo_2020.fillna(Gangwondo_2020.mean())\n",
        "Gyeonggido_2020 = Gyeonggido_2020.fillna(Gyeonggido_2020.mean())\n",
        "Gyeongsangnamdo_2020 = Gyeongsangnamdo_2020.fillna(Gyeongsangnamdo_2020.mean())\n",
        "Gyeongsangbukdo_2020 = Gyeongsangbukdo_2020.fillna(Gyeongsangbukdo_2020.mean())\n",
        "Gwangjusi_2020 = Gwangjusi_2020.fillna(Gwangjusi_2020.mean())\n",
        "Daegusi_2020 = Daegusi_2020.fillna(Daegusi_2020.mean())\n",
        "Daejeonsi_2020 = Daejeonsi_2020.fillna(Daejeonsi_2020.mean())\n",
        "Busansi_2020 = Busansi_2020.fillna(Busansi_2020.mean())\n",
        "Seoulsi_2020 = Seoulsi_2020.fillna(Seoulsi_2020.mean())\n",
        "Sejongsi_2020 = Sejongsi_2020.fillna(Sejongsi_2020.mean())\n",
        "Ulsansi_2020 = Ulsansi_2020.fillna(Ulsansi_2020.mean())\n",
        "Incheonsi_2020 = Incheonsi_2020.fillna(Incheonsi_2020.mean())\n",
        "Jeollanamdo_2020 = Jeollanamdo_2020.fillna(Jeollanamdo_2020.mean())\n",
        "Jeollabukdo_2020 = Jeollabukdo_2020.fillna(Jeollabukdo_2020.mean())\n",
        "Jejudo_2020 = Jejudo_2020.fillna(Jejudo_2020.mean())\n",
        "Chungcheongnamdo_2020 = Chungcheongnamdo_2020.fillna(Chungcheongnamdo_2020.mean())\n",
        "Chungcheongbukdo_2020 = Chungcheongbukdo_2020.fillna(Chungcheongbukdo_2020.mean())"
      ],
      "metadata": {
        "id": "kBQFCvWJlcz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2021 = Gangwondo_2021.fillna(Gangwondo_2021.mean())\n",
        "Gyeonggido_2021 = Gyeonggido_2021.fillna(Gyeonggido_2021.mean())\n",
        "Gyeongsangnamdo_2021 = Gyeongsangnamdo_2021.fillna(Gyeongsangnamdo_2021.mean())\n",
        "Gyeongsangbukdo_2021 = Gyeongsangbukdo_2021.fillna(Gyeongsangbukdo_2021.mean())\n",
        "Gwangjusi_2021 = Gwangjusi_2021.fillna(Gwangjusi_2021.mean())\n",
        "Daegusi_2021 = Daegusi_2021.fillna(Daegusi_2021.mean())\n",
        "Daejeonsi_2021 = Daejeonsi_2021.fillna(Daejeonsi_2021.mean())\n",
        "Busansi_2021 = Busansi_2021.fillna(Busansi_2021.mean())\n",
        "Seoulsi_2021 = Seoulsi_2021.fillna(Seoulsi_2021.mean())\n",
        "Sejongsi_2021 = Sejongsi_2021.fillna(Sejongsi_2021.mean())\n",
        "Ulsansi_2021 = Ulsansi_2021.fillna(Ulsansi_2021.mean())\n",
        "Incheonsi_2021 = Incheonsi_2021.fillna(Incheonsi_2021.mean())\n",
        "Jeollanamdo_2021 = Jeollanamdo_2021.fillna(Jeollanamdo_2021.mean())\n",
        "Jeollabukdo_2021 = Jeollabukdo_2021.fillna(Jeollabukdo_2021.mean())\n",
        "Jejudo_2021 = Jejudo_2021.fillna(Jejudo_2021.mean())\n",
        "Chungcheongnamdo_2021 = Chungcheongnamdo_2021.fillna(Chungcheongnamdo_2021.mean())\n",
        "Chungcheongbukdo_2021 = Chungcheongbukdo_2021.fillna(Chungcheongbukdo_2021.mean())"
      ],
      "metadata": {
        "id": "Pcx4MWtlmb9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2022 = Gangwondo_2022.fillna(Gangwondo_2022.mean())\n",
        "Gyeonggido_2022 = Gyeonggido_2022.fillna(Gyeonggido_2022.mean())\n",
        "Gyeongsangnamdo_2022 = Gyeongsangnamdo_2022.fillna(Gyeongsangnamdo_2022.mean())\n",
        "Gyeongsangbukdo_2022 = Gyeongsangbukdo_2022.fillna(Gyeongsangbukdo_2022.mean())\n",
        "Gwangjusi_2022 = Gwangjusi_2022.fillna(Gwangjusi_2022.mean())\n",
        "Daegusi_2022 = Daegusi_2022.fillna(Daegusi_2022.mean())\n",
        "Daejeonsi_2022 = Daejeonsi_2022.fillna(Daejeonsi_2022.mean())\n",
        "Busansi_2022 = Busansi_2022.fillna(Busansi_2022.mean())\n",
        "Seoulsi_2022 = Seoulsi_2022.fillna(Seoulsi_2022.mean())\n",
        "Sejongsi_2022 = Sejongsi_2022.fillna(Sejongsi_2022.mean())\n",
        "Ulsansi_2022 = Ulsansi_2022.fillna(Ulsansi_2022.mean())\n",
        "Incheonsi_2022 = Incheonsi_2022.fillna(Incheonsi_2022.mean())\n",
        "Jeollanamdo_2022 = Jeollanamdo_2022.fillna(Jeollanamdo_2022.mean())\n",
        "Jeollabukdo_2022 = Jeollabukdo_2022.fillna(Jeollabukdo_2022.mean())\n",
        "Jejudo_2022 = Jejudo_2022.fillna(Jejudo_2022.mean())\n",
        "Chungcheongnamdo_2022 = Chungcheongnamdo_2022.fillna(Chungcheongnamdo_2022.mean())\n",
        "Chungcheongbukdo_2022 = Chungcheongbukdo_2022.fillna(Chungcheongbukdo_2022.mean())"
      ],
      "metadata": {
        "id": "glRU662Vm9gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_2023 = Gangwondo_2023.fillna(Gangwondo_2023.mean())\n",
        "Gyeonggido_2023 = Gyeonggido_2023.fillna(Gyeonggido_2023.mean())\n",
        "Gyeongsangnamdo_2023 = Gyeongsangnamdo_2023.fillna(Gyeongsangnamdo_2023.mean())\n",
        "Gyeongsangbukdo_2023 = Gyeongsangbukdo_2023.fillna(Gyeongsangbukdo_2023.mean())\n",
        "Gwangjusi_2023 = Gwangjusi_2023.fillna(Gwangjusi_2023.mean())\n",
        "Daegusi_2023 = Daegusi_2023.fillna(Daegusi_2023.mean())\n",
        "Daejeonsi_2023 = Daejeonsi_2023.fillna(Daejeonsi_2023.mean())\n",
        "Busansi_2023 = Busansi_2023.fillna(Busansi_2023.mean())\n",
        "Seoulsi_2023 = Seoulsi_2023.fillna(Seoulsi_2023.mean())\n",
        "Sejongsi_2023 = Sejongsi_2023.fillna(Sejongsi_2023.mean())\n",
        "Ulsansi_2023 = Ulsansi_2023.fillna(Ulsansi_2023.mean())\n",
        "Incheonsi_2023 = Incheonsi_2023.fillna(Incheonsi_2023.mean())\n",
        "Jeollanamdo_2023 = Jeollanamdo_2023.fillna(Jeollanamdo_2023.mean())\n",
        "Jeollabukdo_2023 = Jeollabukdo_2023.fillna(Jeollabukdo_2023.mean())\n",
        "Jejudo_2023 = Jejudo_2023.fillna(Jejudo_2023.mean())\n",
        "Chungcheongnamdo_2023 = Chungcheongnamdo_2023.fillna(Chungcheongnamdo_2023.mean())\n",
        "Chungcheongbukdo_2023 = Chungcheongbukdo_2023.fillna(Chungcheongbukdo_2023.mean())"
      ],
      "metadata": {
        "id": "06XwDPmAnV9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gangwondo_test = Gangwondo_test.fillna(Gangwondo_test.mean())\n",
        "Gyeonggido_test = Gyeonggido_test.fillna(Gyeonggido_test.mean())\n",
        "Gyeongsangnamdo_test = Gyeongsangnamdo_test.fillna(Gyeongsangnamdo_test.mean())\n",
        "Gyeongsangbukdo_test = Gyeongsangbukdo_test.fillna(Gyeongsangbukdo_test.mean())\n",
        "Gwangjusi_test = Gwangjusi_test.fillna(Gwangjusi_test.mean())\n",
        "Daegusi_test = Daegusi_test.fillna(Daegusi_test.mean())\n",
        "Daejeonsi_test = Daejeonsi_test.fillna(Daejeonsi_test.mean())\n",
        "Busansi_test = Busansi_test.fillna(Busansi_test.mean())\n",
        "Seoulsi_test = Seoulsi_test.fillna(Seoulsi_test.mean())\n",
        "Sejongsi_test = Sejongsi_test.fillna(Sejongsi_test.mean())\n",
        "Ulsansi_test= Ulsansi_test.fillna(Ulsansi_test.mean())\n",
        "Incheonsi_test = Incheonsi_test.fillna(Incheonsi_test.mean())\n",
        "Jeollanamdo_test = Jeollanamdo_test.fillna(Jeollanamdo_test.mean())\n",
        "Jeollabukdo_test = Jeollabukdo_test.fillna(Jeollabukdo_test.mean())\n",
        "Jejudo_test = Jejudo_test.fillna(Jejudo_test.mean())\n",
        "Chungcheongnamdo_test = Chungcheongnamdo_test.fillna(Chungcheongnamdo_test.mean())\n",
        "Chungcheongbukdo_test = Chungcheongbukdo_test.fillna(Chungcheongbukdo_test.mean())"
      ],
      "metadata": {
        "id": "OvPl7dce_QAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihZIWHZ82gLi"
      },
      "outputs": [],
      "source": [
        "# 시도별 날씨데이터를 합치기\n",
        "sido = pd.concat([Gangwondo_2020, Gyeonggido_2020, Gyeongsangnamdo_2020,Gyeongsangbukdo_2020, Gwangjusi_2020,Daegusi_2020, Daejeonsi_2020, Busansi_2020,\n",
        "           Seoulsi_2020, Sejongsi_2020,Ulsansi_2020, Incheonsi_2020, Jeollanamdo_2020, Jeollabukdo_2020, Jejudo_2020, Chungcheongnamdo_2020, Chungcheongbukdo_2020,\n",
        "                  Gangwondo_2021, Gyeonggido_2021, Gyeongsangnamdo_2021,Gyeongsangbukdo_2021, Gwangjusi_2021,Daegusi_2021, Daejeonsi_2021, Busansi_2021,\n",
        "           Seoulsi_2021, Sejongsi_2021,Ulsansi_2021, Incheonsi_2021, Jeollanamdo_2021, Jeollabukdo_2021, Jejudo_2021, Chungcheongnamdo_2021, Chungcheongbukdo_2021,\n",
        "                  Gangwondo_2022, Gyeonggido_2022, Gyeongsangnamdo_2022,Gyeongsangbukdo_2022, Gwangjusi_2022,Daegusi_2022, Daejeonsi_2022, Busansi_2022,\n",
        "           Seoulsi_2022, Sejongsi_2022,Ulsansi_2022, Incheonsi_2022, Jeollanamdo_2022, Jeollabukdo_2022, Jejudo_2022, Chungcheongnamdo_2022, Chungcheongbukdo_2022,\n",
        "                  Gangwondo_2023, Gyeonggido_2023, Gyeongsangnamdo_2023,Gyeongsangbukdo_2023, Gwangjusi_2023,Daegusi_2023, Daejeonsi_2023, Busansi_2023,\n",
        "           Seoulsi_2023, Sejongsi_2023, Ulsansi_2023, Incheonsi_2023, Jeollanamdo_2023, Jeollabukdo_2023, Jejudo_2023, Chungcheongnamdo_2023, Chungcheongbukdo_2023], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시도별 날씨데이터를 합치기\n",
        "sido_test = pd.concat([Gangwondo_test, Gyeonggido_test, Gyeongsangnamdo_test,Gyeongsangbukdo_test, Gwangjusi_test,Daegusi_test, Daejeonsi_test, Busansi_test,\n",
        "           Seoulsi_test, Sejongsi_test, Ulsansi_test, Incheonsi_test, Jeollanamdo_test, Jeollabukdo_test, Jejudo_test, Chungcheongnamdo_test, Chungcheongbukdo_test], axis = 0)"
      ],
      "metadata": {
        "id": "pWTWyCXQ_yPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euLKg8uz3jqC"
      },
      "outputs": [],
      "source": [
        "# 일시별 날씨데이터의 평균을 데이터프레임 weather에 저장\n",
        "weather = sido.groupby('일시').mean()\n",
        "weather = weather.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일시별 날씨데이터의 평균을 데이터프레임 weather에 저장\n",
        "weather_test = sido_test.groupby('일시').mean()\n",
        "weather_test = weather_test.reset_index()"
      ],
      "metadata": {
        "id": "z5lu50yWAHWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjhe-yVU5BPN"
      },
      "outputs": [],
      "source": [
        "weather['일시'] = pd.to_datetime(weather['일시'])\n",
        "weather_test['일시'] = pd.to_datetime(weather_test['일시'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI9vKRf8VLaW"
      },
      "source": [
        "#### (2) 전력데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzCENWcSQjhV"
      },
      "outputs": [],
      "source": [
        "# datetime 형태로 바꾸기\n",
        "power_1['기준일시'] = pd.to_datetime(power_1['기준일시'])\n",
        "power_2['기준일시'] = pd.to_datetime(power_2['기준일시'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfNVX08ZNVkl"
      },
      "outputs": [],
      "source": [
        "# power 2022년 3월 31일까지 데이터 불러오기\n",
        "power_2022 = power_1[(power_1['기준일시'] >= datetime(2020,1,1, 0, 0)) & (power_1['기준일시'] <= datetime(2022,3,31, 23, 59))]\n",
        "# power 2023년 3월 12일까지 데이터 불러오기\n",
        "power_2023 = power_2[(power_2['기준일시'] >= datetime(2022,4,1, 0, 0)) & (power_2['기준일시'] <= datetime(2023,3,12, 23, 59))]\n",
        "# 2023.03.13 - 2023.03.19 예측을 위한 데이터\n",
        "power_test = power_2[(power_2['기준일시'] >= datetime(2023,3,13, 0, 0)) & (power_2['기준일시'] <= datetime(2023,3,20, 5, 59))]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power = pd.concat([power_2022, power_2023], axis = 0)"
      ],
      "metadata": {
        "id": "LBXn4EVHtg2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (3) 발전량 데이터"
      ],
      "metadata": {
        "id": "85WBtOOJ8ivR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datetime 형태로 바꾸기\n",
        "energy1['거래일자'] = pd.to_datetime(energy1['거래일자'])\n",
        "energy2['거래일자'] = pd.to_datetime(energy2['거래일자'])"
      ],
      "metadata": {
        "id": "p5lJysQmcsXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2020년 이후 데이터 불러오기\n",
        "from datetime import datetime\n",
        "energy_2020 = energy1[energy1['거래일자'] >= datetime(2020,1,1, 0, 0)]\n",
        "energy_2023 = energy2[energy2['거래일자'] <= datetime(2023,3,20, 7, 0)]"
      ],
      "metadata": {
        "id": "aAUXmUf0dDAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼명 지정\n",
        "energy_2020.columns = ['거래일자', '거래시간', '지역', '태양광 발전량', '풍력 발전량']\n",
        "energy_2023.columns = ['거래일자', '거래시간', '지역', '태양광 발전량', '풍력 발전량']"
      ],
      "metadata": {
        "id": "vnvT8sbgkuZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2020년 1월 ~ 2023년 3월 20일 데이터 합치기\n",
        "energy = pd.concat([energy_2020, energy_2023], axis = 0)"
      ],
      "metadata": {
        "id": "KmNcV4nadxWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결측치 채우기"
      ],
      "metadata": {
        "id": "EDhfUVZLmeJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 풍력발전량의 결측은 0으로 대치\n",
        "energy['풍력 발전량'] = energy['풍력 발전량'].fillna(0)"
      ],
      "metadata": {
        "id": "_a8y197QfwMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGh50yZqfwgM"
      },
      "outputs": [],
      "source": [
        "# 공백(결측) 데이터를 0으로 변환\n",
        "energy['태양광 발전량'] = energy['태양광 발전량'].replace('   ', 0)\n",
        "energy['풍력 발전량'] = energy['풍력 발전량'].replace('   ', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmUaGFAxm_ht"
      },
      "outputs": [],
      "source": [
        "# 숫자 데이터에 포함된 콤마를 공백으로 바꿔주기(콤마 때문에 문자로 인식하는중)\n",
        "for i in range(len(energy)) :\n",
        "  energy.iloc[i, 3] = str(energy.iloc[i, 3]).replace(',', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6RwIBAYiIV5"
      },
      "outputs": [],
      "source": [
        "# 태양광 발전량. 풍력 발전량을 숫자 타입으로 변경\n",
        "energy['태양광 발전량'] = energy['태양광 발전량'].astype('float')\n",
        "energy['풍력 발전량'] = energy['풍력 발전량'].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "energy = energy.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "QHLL-wZiqwr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 거래일자, 거래시간 변수를 이용하여 파생변수 기준일시 생성\n",
        "from datetime import datetime\n",
        "year_energy = energy['거래일자'].dt.year\n",
        "month_energy = energy['거래일자'].dt.month\n",
        "day_energy = energy['거래일자'].dt.day\n",
        "for i in range(len(energy)):\n",
        "  energy.loc[i,'기준일시'] = datetime(year_energy[i], month_energy[i], day_energy[i], energy.iloc[i,1]-1) # 0~23시로 바꾸기 위해 -1을 해주었음"
      ],
      "metadata": {
        "id": "SyJbl9bWesHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요하지 않은 변수 제거\n",
        "energy_total = energy.drop(['거래일자','거래시간','지역'],axis = 1)"
      ],
      "metadata": {
        "id": "ctB0tApVfk3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기준일시를 기준으로 모든 지역 데이터 평균 값 이용\n",
        "energy_total= energy_total.groupby('기준일시').mean()\n",
        "energy_total = energy_total.reset_index()"
      ],
      "metadata": {
        "id": "QreTX5jFfnMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_train = energy_total[energy_total['기준일시'] <= datetime(2023,3,12, 23, 0)]\n",
        "energy_test = energy_total[(energy_total['기준일시'] >= datetime(2023,3,13, 0, 0)) & (energy_total['기준일시'] <= datetime(2023,3,20,6,0))]"
      ],
      "metadata": {
        "id": "CNNVpydcykLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkUiP6Nb7qQa"
      },
      "source": [
        "#### (4) join/merge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- power, weather 데이터 합치기"
      ],
      "metadata": {
        "id": "4nhSwwuq9WqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srp79peI8iyt"
      },
      "outputs": [],
      "source": [
        "weather.rename(columns = {'일시' : '기준일시'}, inplace = True)\n",
        "weather_test.rename(columns = {'일시' : '기준일시'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5_oPoPX-5lK"
      },
      "outputs": [],
      "source": [
        "# 전력 데이터와 날씨데이터 합치기\n",
        "data = pd.merge(power, weather, left_on = [power['기준일시'].dt.year,power['기준일시'].dt.month,power['기준일시'].dt.day,power['기준일시'].dt.hour],\n",
        "         right_on = [weather['기준일시'].dt.year,weather['기준일시'].dt.month,weather['기준일시'].dt.day,weather['기준일시'].dt.hour])\n",
        "\n",
        "test = pd.merge(power_test, weather_test, left_on = [power_test['기준일시'].dt.year,power_test['기준일시'].dt.month,power_test['기준일시'].dt.day,power_test['기준일시'].dt.hour],\n",
        "         right_on = [weather_test['기준일시'].dt.year,weather_test['기준일시'].dt.month,weather_test['기준일시'].dt.day,weather_test['기준일시'].dt.hour])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XLuDB75Bde0"
      },
      "outputs": [],
      "source": [
        "# 분석에 필요하지 않은 컬럼 제거\n",
        "data.drop(['key_0', 'key_1', 'key_2','key_3', '기준일시_y'], axis = 1, inplace = True)\n",
        "test.drop(['key_0', 'key_1', 'key_2','key_3', '기준일시_y'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejfVvJBBBufN"
      },
      "outputs": [],
      "source": [
        "data.rename(columns = {'기준일시_x' : '기준일시'}, inplace = True)\n",
        "test.rename(columns = {'기준일시_x' : '기준일시'}, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- data, energy 데이터 합치기"
      ],
      "metadata": {
        "id": "KA5183Os9a9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_join = pd.merge(data, energy_train, left_on = [data['기준일시'].dt.year,data['기준일시'].dt.month,data['기준일시'].dt.day,data['기준일시'].dt.hour],\n",
        "         right_on = [energy_train['기준일시'].dt.year,energy_train['기준일시'].dt.month,energy_train['기준일시'].dt.day,energy_train['기준일시'].dt.hour])"
      ],
      "metadata": {
        "id": "AhaRFHbpyaEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_join = pd.merge(test, energy_test, left_on = [test['기준일시'].dt.year,test['기준일시'].dt.month,test['기준일시'].dt.day,test['기준일시'].dt.hour],\n",
        "         right_on = [energy_test['기준일시'].dt.year,energy_test['기준일시'].dt.month,energy_test['기준일시'].dt.day,energy_test['기준일시'].dt.hour])"
      ],
      "metadata": {
        "id": "5hOQOtQKzuvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uvWj3q40IEk"
      },
      "outputs": [],
      "source": [
        "data_join.drop(['key_0', 'key_1', 'key_2','key_3', '기준일시_y'], axis = 1, inplace = True)\n",
        "test_join.drop(['key_0', 'key_1', 'key_2','key_3', '기준일시_y'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPZMKOLI0IFE"
      },
      "outputs": [],
      "source": [
        "data_join.rename(columns = {'기준일시_x' : '기준일시'}, inplace = True)\n",
        "test_join.rename(columns = {'기준일시_x' : '기준일시'}, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 변수 month 만들기"
      ],
      "metadata": {
        "id": "3F5NLXz99dtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 월 변수 만들기\n",
        "data_join['month'] = data_join['기준일시'].dt.month\n",
        "test_join['month'] = test_join['기준일시'].dt.month"
      ],
      "metadata": {
        "id": "uRjvMXyq8fk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 변수명 지정"
      ],
      "metadata": {
        "id": "_qL8sXDp9tG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sd : 기준일시 (standard date)\n",
        "\n",
        "sc : 공급능력 (supply capacity)\n",
        "\n",
        "cd : 현재수요 (current demand)\n",
        "\n",
        "mpd : 최대예측수요 (maximum predicted demand)\n",
        "\n",
        "sr : 공급예비력 (supply reserve)\n",
        "\n",
        "srr : 공급예비율 (supply reserve ratio)\n",
        "\n",
        "or : 운영예비력 (operating resrve)\n",
        "\n",
        "orr : 운영예비율 (operating reserve ratio)\n",
        "\n",
        "p : 지점 (point)\n",
        "\n",
        "T : 기온 (temperatures)\n",
        "\n",
        "pt : 강수량 (precipitation)\n",
        "\n",
        "ws : 풍속 (wind speed)\n",
        "\n",
        "h : 습도 (Humidity)\n",
        "\n",
        "dp : 이슬점온도(dew point)\n",
        "\n",
        "ap : 현지기압 (atmospheric pressure)\n",
        "\n",
        "gt : 지면온도(groung temperature)\n",
        "\n",
        "s : 태양광발전량\n",
        "\n",
        "w : 풍력발전량\n",
        "\n",
        "month : 월"
      ],
      "metadata": {
        "id": "UUhcevzFOkCs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KuAh2ldPYPw"
      },
      "outputs": [],
      "source": [
        "data_join.columns = ['sd', 'sc', 'cd', 'mpd', 'sr', 'srr',\n",
        "       'or', 'orr', 'p', 'T', 'pt', 'ws', 'h', 'dp', 'ap',\n",
        "       'gt','s','w','month']\n",
        "\n",
        "test_join.columns = ['sd', 'sc', 'cd', 'mpd', 'sr', 'srr',\n",
        "       'or', 'orr', 'p', 'T', 'pt', 'ws', 'h', 'dp', 'ap',\n",
        "       'gt', 's', 'w', 'month']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZAO_wEXKXQo"
      },
      "source": [
        "#### (5) 변수간 상관관계 파악"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "aqpuO5jPPzsK",
        "outputId": "86a432af-6e3a-4a4e-d728-6431cf6062b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def show_heatmap(data):\n",
        "    plt.matshow(data.corr())\n",
        "    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
        "\n",
        "    cb = plt.colorbar()\n",
        "    cb.ax.tick_params(labelsize=14)\n",
        "    plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_heatmap(data_join)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UujbCtLlQPWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "a09bf036-53e9-4577-f0f6-40c9b7e10233"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sd   sc        cd       mpd        sr       srr        or       orr  \\\n",
              "sd     1.0  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "sc     NaN  1.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "cd     NaN  NaN  1.000000  0.780866       NaN       NaN       NaN       NaN   \n",
              "mpd    NaN  NaN  0.780866  1.000000       NaN       NaN       NaN       NaN   \n",
              "sr     NaN  NaN       NaN       NaN  1.000000  0.951477       NaN       NaN   \n",
              "srr    NaN  NaN       NaN       NaN  0.951477  1.000000       NaN       NaN   \n",
              "or     NaN  NaN       NaN       NaN       NaN       NaN  1.000000  0.927424   \n",
              "orr    NaN  NaN       NaN       NaN       NaN       NaN  0.927424  1.000000   \n",
              "p      NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "T      NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "pt     NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "ws     NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "h      NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "dp     NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "ap     NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "gt     NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "s      NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "w      NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "month  NaN  NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "\n",
              "         p         T   pt   ws    h        dp   ap        gt    s    w  month  \n",
              "sd     NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "sc     NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "cd     NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "mpd    NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "sr     NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "srr    NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "or     NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "orr    NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "p      1.0       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "T      NaN  1.000000  NaN  NaN  NaN  0.928073  NaN  0.947799  NaN  NaN    NaN  \n",
              "pt     NaN       NaN  1.0  NaN  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "ws     NaN       NaN  NaN  1.0  NaN       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "h      NaN       NaN  NaN  NaN  1.0       NaN  NaN       NaN  NaN  NaN    NaN  \n",
              "dp     NaN  0.928073  NaN  NaN  NaN  1.000000  NaN  0.810976  NaN  NaN    NaN  \n",
              "ap     NaN       NaN  NaN  NaN  NaN       NaN  1.0       NaN  NaN  NaN    NaN  \n",
              "gt     NaN  0.947799  NaN  NaN  NaN  0.810976  NaN  1.000000  NaN  NaN    NaN  \n",
              "s      NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  1.0  NaN    NaN  \n",
              "w      NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  1.0    NaN  \n",
              "month  NaN       NaN  NaN  NaN  NaN       NaN  NaN       NaN  NaN  NaN    1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de1eaa5f-c3d4-4e69-b578-2cc0c413bc4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sd</th>\n",
              "      <th>sc</th>\n",
              "      <th>cd</th>\n",
              "      <th>mpd</th>\n",
              "      <th>sr</th>\n",
              "      <th>srr</th>\n",
              "      <th>or</th>\n",
              "      <th>orr</th>\n",
              "      <th>p</th>\n",
              "      <th>T</th>\n",
              "      <th>pt</th>\n",
              "      <th>ws</th>\n",
              "      <th>h</th>\n",
              "      <th>dp</th>\n",
              "      <th>ap</th>\n",
              "      <th>gt</th>\n",
              "      <th>s</th>\n",
              "      <th>w</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sd</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sc</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cd</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.780866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mpd</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.780866</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sr</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.951477</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>srr</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.951477</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>or</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.927424</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>orr</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.927424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>p</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.928073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.947799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pt</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ws</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.928073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.810976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ap</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gt</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.947799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.810976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de1eaa5f-c3d4-4e69-b578-2cc0c413bc4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de1eaa5f-c3d4-4e69-b578-2cc0c413bc4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de1eaa5f-c3d4-4e69-b578-2cc0c413bc4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c588971d-962f-4d45-b276-b712342a221e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c588971d-962f-4d45-b276-b712342a221e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c588971d-962f-4d45-b276-b712342a221e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_join\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15495124158643186,\n        \"min\": 0.7808658526419181,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7808658526419181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mpd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15495124158643186,\n        \"min\": 0.7808658526419181,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0343106553353608,\n        \"min\": 0.951477405890824,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.951477405890824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"srr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0343106553353608,\n        \"min\": 0.951477405890824,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"or\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05131877321072887,\n        \"min\": 0.9274242949210382,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9274242949210382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"orr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05131877321072887,\n        \"min\": 0.9274242949210382,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.037165523597042865,\n        \"min\": 0.9280725746494665,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ws\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"h\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09540741886294214,\n        \"min\": 0.8109756430228774,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9280725746494665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09761806096757138,\n        \"min\": 0.8109756430228774,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9477985983093709\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# 변수 간 상관성 확인\n",
        "data_join.corr()[data_join.corr()>0.7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRxUgJsnRX_i"
      },
      "outputs": [],
      "source": [
        "# 상관성 높은 변수들 제거\n",
        "data_join.drop(['mpd', 'srr', 'gt', 'sd','orr', 'dp','p'], axis = 1, inplace = True)\n",
        "test_join.drop(['mpd', 'srr', 'gt', 'sd','orr', 'dp','p'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DYh5c1e70vC"
      },
      "source": [
        "### 5. 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmmRvJizPpUo"
      },
      "outputs": [],
      "source": [
        "# 파라미터 지정\n",
        "split_fraction = 0.7\n",
        "train_split = int(split_fraction * int(data_join.shape[0]))\n",
        "past = 1440  # 5일 데이터 이용하여 미래예측\n",
        "future = 1   # 뒤의 1시점 예측\n",
        "learning_rate = 0.01\n",
        "batch_size = 128\n",
        "epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화 함수\n",
        "def normalize(data,m,s) :\n",
        "  data_mean = m\n",
        "  data_std = s\n",
        "  return (data-data_mean) / data_std"
      ],
      "metadata": {
        "id": "Ytp1nTTznyFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화\n",
        "m = data_join[:train_split].mean(axis=0)\n",
        "s = data_join[:train_split].std(axis=0)\n",
        "\n",
        "features = normalize(data_join, m,s)\n",
        "features = pd.DataFrame(features)\n",
        "test_data = normalize(test_join, m, s)"
      ],
      "metadata": {
        "id": "Td-nqjlBoa4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분할\n",
        "train_data = features.loc[0 : train_split - 1]\n",
        "val_data = features.loc[train_split:]"
      ],
      "metadata": {
        "id": "7FMqVLUlV8vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievMsDtfKQ_c"
      },
      "source": [
        "#### training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l-2W1B6KtzV"
      },
      "outputs": [],
      "source": [
        "# window_size 설정 (6시간 예측해야 하므로 12*6 = 72로 설정)\n",
        "window_size = 72"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns = range(12)\n",
        "val_data.columns = range(12)"
      ],
      "metadata": {
        "id": "BTP4i03TbVw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il2TkxkGKU6T"
      },
      "outputs": [],
      "source": [
        "# train_x, train_y 생성\n",
        "start = past + future\n",
        "end = start + train_split\n",
        "train_X = train_data[[i for i in range(12)]].values\n",
        "train_y = data_join.iloc[start:end][['cd']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev1qANlIRUng"
      },
      "outputs": [],
      "source": [
        "# 이후 72시점의 cd를 y로 지정 (즉 72열을 가짐)\n",
        "y_train = []\n",
        "for i in range(len(train_y) - window_size):\n",
        "    _Y = train_y[i : i + window_size]\n",
        "    y_train.append(_Y)\n",
        "Y = np.array(y_train).reshape(len(train_y)-72,72)\n",
        "Y = pd.DataFrame(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxkz0HaYe7Id"
      },
      "outputs": [],
      "source": [
        "# valid x, valid_y 만들기\n",
        "\n",
        "x_end = len(val_data) - past - future\n",
        "label_start = train_split + past + future\n",
        "val_X = val_data.iloc[:x_end][[i for i in range(12)]].values\n",
        "val_y = data_join.iloc[label_start:][['cd']]\n",
        "\n",
        "\n",
        "y_valid = []\n",
        "for i in range(len(val_y) - window_size):\n",
        "    _Y = val_y[i : i + window_size] # 다음 날 종가(i+windows_size)는 포함되지 않음\n",
        "    y_valid.append(_Y)\n",
        "\n",
        "Y_val = np.array(y_valid).reshape(len(val_y)-72,72)\n",
        "Y_val = pd.DataFrame(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2023.03.13 - 2023.03.19까지의 데이터(2016개)를 x 데이터로 사용\n",
        "x = test_data.iloc[:2016]\n",
        "x.columns = range(12)"
      ],
      "metadata": {
        "id": "zFSI-yGhse_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X = x.iloc[:][[i for i in range(12)]].values\n",
        "test_y = test_join[:][['cd']]"
      ],
      "metadata": {
        "id": "1qvfxSQAfGjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이후 72시점의 cd를 y로 지정 (즉 72열을 가짐)\n",
        "# 2023.03.13 - 2023.03.19의 5분단위 6시간 후까지의 'cd' 실제값을 test_Y로 지정\n",
        "y_test = []\n",
        "for i in range(len(test_y) - window_size):\n",
        "    _Y = test_y[i : i + window_size]\n",
        "    y_test.append(_Y)\n",
        "Y_test = np.array(y_test).reshape(len(test_y)-72,72)\n",
        "test_Y = pd.DataFrame(Y_test)"
      ],
      "metadata": {
        "id": "dDzdG-YwgN5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) 랜덤포레스트"
      ],
      "metadata": {
        "id": "myck8sFmeWrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### RandomForest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 25)\n",
        "rf.fit(train_X[:len(train_X)-72], Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "7chCHqTYmnKc",
        "outputId": "7b3d7a56-2290-4966-aff5-17e0113390d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=25)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=25)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_rf = rf.predict(val_X[:len(val_X)-72])"
      ],
      "metadata": {
        "id": "HGSKdyLNnMaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(Y_val, pred_rf) # 0.0941"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHLWe1vmubwr",
        "outputId": "36018de9-7933-4b8a-f6c8-892fbe7c0262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09412051121864337"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = rf.predict(test_X)"
      ],
      "metadata": {
        "id": "oLOmmNKS1olB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분석대상기간(23.03.13-23.03.19)의 mape 결과\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(test_Y, pred_test) #0.1007"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdd2d43-1bad-4dfb-9165-2b311475a01e",
        "id": "ORg7j4b31olJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10073088108448214"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) LightGBM"
      ],
      "metadata": {
        "id": "3L7uZsLcfTBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "향후 6시간의 전력수요량을 예측해야 하는데, LightGBM 5분(1시점) 뒤의 전력수요량만 예측하기 때문에, for문을 이용하여 5분 뒤를 예측하는 모델부터, 6시간 뒤를 예측하는 모델까지 총 72개의 모델을 학습했다."
      ],
      "metadata": {
        "id": "ycPS2NlyfXTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as ltb\n",
        "lgb = ltb.LGBMRegressor(learning_rate = 0.04, max_depth = 10, metric = 'mape')"
      ],
      "metadata": {
        "id": "zPM-iLTb8ye4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in range(72):\n",
        "  lgb.fit(train_X[:len(train_X)-72], Y[[i]])\n",
        "  pred.append(lgb.predict(val_X[:len(val_X)-72]))"
      ],
      "metadata": {
        "id": "snyOwPgk-1D5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb289495-3f4d-47ea-b84c-c68e4fbc220c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.030921\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.070060\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010308 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.111836\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031595 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.153749\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018236 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.198548\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.245457\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.294073\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.341882\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009965 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.390282\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046750 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.438171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.484679\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.530993\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.577880\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009585 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.623995\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016697 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.669635\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.713718\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.758377\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.802666\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016573 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.843590\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.884252\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009815 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.925072\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010356 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.965175\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009801 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.003311\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051103 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.043120\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.083049\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.122806\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010074 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.162333\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009675 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.200221\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016035 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.239586\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.276419\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.311195\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010254 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.344178\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.376593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.409948\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009898 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.443103\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010379 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.474988\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009818 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.505095\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.534935\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.564917\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010036 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.595878\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009650 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.626248\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010239 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.655657\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.684047\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.713712\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010589 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.741052\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.768821\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009728 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.795002\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.819666\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010583 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.843009\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.865752\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009982 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.887873\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009615 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.910006\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.931143\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009761 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.952121\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009828 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.975733\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.997019\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016314 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.017687\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010367 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.038395\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.055843\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010237 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.072211\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.083228\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017320 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.093729\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.101720\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.108537\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.112175\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010188 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.111211\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050392 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.108382\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009672 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.103726\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010035 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.095782\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009828 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.086254\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015587 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.072847\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.056417\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_lgb = np.array(pred).reshape(72,-1)"
      ],
      "metadata": {
        "id": "WipJIoc8AjMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lgb = pd.DataFrame(np.transpose(Y_lgb))"
      ],
      "metadata": {
        "id": "Rx9JrV9SA24n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_percentage_error(Y_val, pred_lgb) # 0.0865"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iknq51_U9e2L",
        "outputId": "b128daa1-261a-45a7-f490-aadde6656725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08657261242555095"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (3) Bagging"
      ],
      "metadata": {
        "id": "6SSVSdl3idOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### bagging regressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "bag = BaggingRegressor(n_estimators = 20,\n",
        "                       max_samples = 0.5)\n",
        "bag.fit(train_X[:len(train_X)-72], Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9-f0HxIFwJHk",
        "outputId": "c80be85d-2260-41e8-8e10-004dc7937153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingRegressor(max_samples=0.5, n_estimators=20)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(max_samples=0.5, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(max_samples=0.5, n_estimators=20)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_bag = bag.predict(val_X[:len(val_X)-72])"
      ],
      "metadata": {
        "id": "F8CkJLONwwMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(Y_val, pred_bag) # 0.0932"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96A0Xjruw38r",
        "outputId": "015ecf0f-cacd-4b91-b992-a61be9de353f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09323315370297049"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = bag.predict(test_X)"
      ],
      "metadata": {
        "id": "B-sIeCOBGBUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분석대상기간(23.03.13-23.03.19)의 mape 결과\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(test_Y, pred_test) #0.09772"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51de371c-97c8-4120-d65a-eb929dcb7755",
        "id": "P8rJxPO5GBUg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09772466045635574"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 제출"
      ],
      "metadata": {
        "id": "v1BBAaTK2dXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "세가지 모델 중 lightgbm 모델의 성능이 가장 좋았기 때문에 lightgbm 모델을 이용해 분석대상기간의 mape를 구하였다."
      ],
      "metadata": {
        "id": "gvdvEGkPjsRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in range(72):\n",
        "  lgb.fit(train_X[:len(train_X)-72], Y[[i]])\n",
        "  pred.append(lgb.predict(test_X))"
      ],
      "metadata": {
        "id": "NNNByHTNMZRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3992cad0-d737-470b-fc72-3939853911c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.030921\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009666 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.070060\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009873 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.111836\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.153749\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.198548\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.245457\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016263 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.294073\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009734 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.341882\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009708 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.390282\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.438171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.484679\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.530993\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015587 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.577880\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009889 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.623995\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.669635\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010077 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.713718\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.758377\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016641 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.802666\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009918 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.843590\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010018 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.884252\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.925072\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009715 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63654.965175\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009796 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.003311\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015928 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.043120\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009595 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.083049\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009988 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.122806\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.162333\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009541 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.200221\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.239586\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048079 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.276419\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010571 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.311195\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009868 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.344178\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.376593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009683 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.409948\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015672 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.443103\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.474988\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.505095\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010978 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.534935\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010061 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.564917\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009777 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.595878\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.626248\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009685 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.655657\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.684047\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.713712\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009505 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.741052\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018128 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.768821\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.795002\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.819666\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032208 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.843009\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009748 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.865752\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009725 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.887873\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046456 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.910006\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009530 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.931143\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.952121\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.975733\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63655.997019\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015463 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.017687\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.038395\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010079 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.055843\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.072211\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009739 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.083228\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.093729\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011946 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.101720\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009705 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.108537\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.112175\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009954 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.111211\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009721 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.108382\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.103726\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009897 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.095782\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.086254\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010592 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.072847\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2818\n",
            "[LightGBM] [Info] Number of data points in the train set: 234868, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 63656.056417\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_lgb = np.array(pred).reshape(72,-1)\n",
        "pred_test = pd.DataFrame(np.transpose(Y_lgb))"
      ],
      "metadata": {
        "id": "1MJkyVnjMmkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분석대상기간(23.03.13-23.03.19)의 mape 결과\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(test_Y, pred_test) # 0.0916"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81900839-28ff-41b1-8f77-2b231d10be85",
        "id": "m70YfZm9L5FS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09169184958402099"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test.to_csv('/content/drive/MyDrive/2023 공공데이터 활용 공모전/predict.csv', index=False)"
      ],
      "metadata": {
        "id": "4SvnNfcS964O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "분석 대상 기간(23.03.13-23.03.19)의 mape 결과는 0.0916이다."
      ],
      "metadata": {
        "id": "8D-sc8ygjeJr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYIneunCm4oIB0rYBz2k2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}